{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nominated-special",
   "metadata": {},
   "source": [
    "# Welcome to <font color='red'>BE</font>yond <font color='red'>T</font>witter <font color='red'>A</font>nalytics, or <font color='red'>BETA</font>:\n",
    "\n",
    "### an app for small business and social media influencers to dig deeper into their advertisements and maximize follower-base growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "higher-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from analysis import process_fch, process_tweets, format_ticks, analyze_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fatty-albert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note, for now (until the app is public), please enter the Twitter handle and associated Tweet archive file name for one of the available archives listed here:\n",
      "\n",
      "dog_rates, dog_rates_tweet.json\n",
      "\n",
      "\n",
      "In the future, users will be able to upload the /data/tweet.js file from their account's downloaded Twitter archive.\n"
     ]
    }
   ],
   "source": [
    "available_archives = sorted(glob.glob('archives/*_tweet.json'))\n",
    "\n",
    "print('Note, for now (until the app is public), please enter the Twitter handle and associated Tweet archive file name for one of the available archives listed here:\\n')\n",
    "for arc in available_archives:\n",
    "    print('{}, {}\\n'.format(arc.replace('archives/', '').replace('_tweet.json',''), arc.replace('archives/', '')))\n",
    "    \n",
    "print('\\nIn the future, users will be able to upload the /data/tweet.js file from their account\\'s downloaded Twitter archive.')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-jenny",
   "metadata": {},
   "source": [
    "### To get started, we need to know:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "embedded-independence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the Twitter handle of the account you want to run BETA on?\n",
      "  dog_rates\n"
     ]
    }
   ],
   "source": [
    "thandle = input('What is the Twitter handle of the account you want to run BETA on?\\n  ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "plastic-stage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload the account's Twitter archive:\n",
      "  dog_rates_tweet.json\n"
     ]
    }
   ],
   "source": [
    "tweet_file = input('Upload the account\\'s Twitter archive:\\n  ')\n",
    "assert os.path.exists(os.path.join('archives', tweet_file)), 'File path does not exist. Make sure you entered the path correctly and try again.'\n",
    "tweet_file = os.path.join('archives', tweet_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-apparatus",
   "metadata": {},
   "source": [
    "### Great!\n",
    "\n",
    "### Now let's pull your historical follower data and start searching for ads that have lost and gained you the most followers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stone-introduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter handle: @dog_rates\n",
      "\n",
      "Formatting historical follower count archive...\n",
      "Done!\n",
      "\n",
      "Formatting Tweet archive...\n",
      "Done!\n",
      "\n",
      "Combining historical follower count and Tweet archives...\n",
      "Done!\n",
      "\n",
      "Running clustering algorithm. Some human interaction necessary here...\n",
      "\n",
      "\n",
      "====================\n",
      "Cluster 1 (Number of Tweets: 3680)\n",
      "Most tweets are replies? True\n",
      "Most tweets include media? False\n",
      "Hashtags:\n",
      "URLS:\n",
      "     weratedogs\n",
      "     twitter\n",
      "N_Favorites 290\n",
      "N_Retweets 1\n",
      "====================\n",
      "\n",
      "\n",
      "====================\n",
      "Cluster 2 (Number of Tweets: 483)\n",
      "Most tweets are replies? False\n",
      "Most tweets include media? True\n",
      "Hashtags:\n",
      "     SeniorPupSaturday\n",
      "URLS:\n",
      "     twitter\n",
      "     gofundme\n",
      "N_Favorites 111598\n",
      "N_Retweets 10922\n",
      "====================\n",
      "\n",
      "\n",
      "====================\n",
      "Cluster 3 (Number of Tweets: 129)\n",
      "Most tweets are replies? False\n",
      "Most tweets include media? True\n",
      "Hashtags:\n",
      "     PrideMonthPuppo\n",
      "     SeniorPupSaturday\n",
      "URLS:\n",
      "     twitter\n",
      "N_Favorites 208278\n",
      "N_Retweets 27511\n",
      "====================\n",
      "\n",
      "\n",
      "====================\n",
      "Cluster 4 (Number of Tweets: 9)\n",
      "Most tweets are replies? False\n",
      "Most tweets include media? True\n",
      "Hashtags:\n",
      "URLS:\n",
      "N_Favorites 486111\n",
      "N_Retweets 105297\n",
      "====================\n",
      "\n",
      "\n",
      "====================\n",
      "Cluster 5 (Number of Tweets: 394)\n",
      "Most tweets are replies? False\n",
      "Most tweets include media? True\n",
      "Hashtags:\n",
      "     TrupanionPartner\n",
      "     partner\n",
      "     SeniorPupSaturday\n",
      "     RoyalCaninPuppies\n",
      "URLS:\n",
      "     gofundme\n",
      "     weratedogs\n",
      "     twitter\n",
      "N_Favorites 30407\n",
      "N_Retweets 2360\n",
      "====================\n",
      "Based on the table above, which cluster seems to be mostly made up of ad Tweets?\n",
      "Cluster 5\n",
      "Thanks!\n",
      "\n",
      "Finding ads that caused significant follower losses/gains...\n",
      "Done!\n",
      "\n",
      "Writing report...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_data.get_data(thandle, tweet_file)\n",
    "\n",
    "tweets = analyze_data.combine_archives(thandle)\n",
    "\n",
    "ad_cluster = analyze_data.cluster_tweets(thandle, tweets)\n",
    "\n",
    "gainy_tweets, lossy_tweets = analyze_data.sig_follower_change(tweets, ad_cluster)\n",
    "\n",
    "analyze_data.report(thandle, gainy_tweets, lossy_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-blogger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
